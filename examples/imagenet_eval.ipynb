{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6f0af6",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with TransAxx on ImageNet dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models.\n",
    "You can also retrain the model for further accuracy improvement\n",
    "\n",
    "**Note**:\n",
    "* Currently, the quantization bitwidth supported is 8bit and supported layers are Conv2d and Linear\n",
    "\n",
    "* Please make sure you have run the installation steps first\n",
    "\n",
    "* This example notebook approximates Linear layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.utils import *\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbe30f",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Provide an ImageNet dataset with the structure below (Use the 'imagenet_data' path)\n",
    "\n",
    "imagenet_data/\n",
    "\n",
    "└── val/\n",
    "\n",
    "└── train_tiny/\n",
    "\n",
    "**Note**: 'val' is the validation dataset and 'train_tiny' should be a small train dataset used for calibration purposes. Change batch size if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902efbd-c957-4610-a009-d68fd9b6b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, calib_data = imagenet_data_loader('datasets/imagenet_data', batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae3e54",
   "metadata": {},
   "source": [
    "## Select a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "\n",
    "model_name = 'vit_small_patch16_224'\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid frequent downloading of the weights the following commands might be handy\n",
    "\n",
    "#torch.save(model, 'models/' + model_name + '.pth')\n",
    "#model = timm.create_model(model_name).to(device)\n",
    "#model.load_state_dict(torch.load('models/' + model_name + '.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2e8b9-0c1c-4a5e-b0f9-8c1c55d8dead",
   "metadata": {},
   "source": [
    "## Optional: Evaluate default model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cd8c3-cdd3-47af-b7dc-ea677f9df40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = evaluate_cifar10(model, val_data, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4183a",
   "metadata": {},
   "source": [
    "## Initialize model with axx layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear layers to approximate\n",
    "linear_layers = [(name, module) for name, module in model.named_modules() if (isinstance(module, torch.nn.Linear) or  isinstance(module, AdaPT_Linear)) and (\"head\" not in name and \"reduction\" not in name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2db2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b65a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with all required approximate multipliers for axx layers. \n",
    "# No explicit assignment needed; this step JIT compiles all upcoming multipliers\n",
    "\n",
    "axx_list = [{'axx_mult' : 'mul8s_acc', 'axx_power' : 1.0, 'quant_bits' : 8, 'fake_quant' : False}]*len(linear_layers)\n",
    "\n",
    "axx_list[1:2] = [{'axx_mult' : 'mul8s_1L2H', 'axx_power' : 0.7082, 'quant_bits' : 8, 'fake_quant' : False}] * 1\n",
    "\n",
    "start = time.time()\n",
    "replace_linear_layers(model,  AdaPT_Linear, axx_list, 0, 0, layer_count=[0], returned_power = [0], initialize = True)  \n",
    "print('Time to compile cuda extensions: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ada14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure flops of model and compute 'flops' in every layer\n",
    "\n",
    "import io\n",
    "from classification.ptflops import get_model_complexity_info\n",
    "from classification.ptflops.pytorch_ops import linear_flops_counter_hook\n",
    "from classification.ptflops.pytorch_ops import conv_flops_counter_hook\n",
    "\n",
    "#hook our custom axx_layers in the appropriate flop counters, i.e. AdaPT_Linear : linear_flops_counter_hook\n",
    "with torch.cuda.device(0):\n",
    "    total_macs, total_params, layer_specs = get_model_complexity_info(model, (3, 224, 224),as_strings=False, print_per_layer_stat=True,\n",
    "                                                          custom_modules_hooks={AdaPT_Linear : linear_flops_counter_hook}, \n",
    "                                                          param_units='M', flops_units='MMac',\n",
    "                                                          verbose=True)\n",
    "\n",
    "print(f'Computational complexity:  {total_macs/1000000:.2f} MMacs')\n",
    "print(f'Number of parameters::  {total_params/1000000:.2f} MParams')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4f461",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the initial model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, calib_data, num_batches=2, device=device)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99, device=device)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a48a6e",
   "metadata": {},
   "source": [
    "## Run model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set desired approximate multiplier in each layer\n",
    "\n",
    "#at first, set all layers to have the 8-bit accurate multiplier\n",
    "axx_list = [{'axx_mult' : 'mul8s_acc', 'axx_power' : 1.0, 'quant_bits' : 8, 'fake_quant' : False}]*len(linear_layers)\n",
    "\n",
    "# For example, set the first 5 layers to be approximated with a specific multiplier \n",
    "axx_list[0:5] = [{'axx_mult' : 'mul8s_1L2H', 'axx_power' : 0.7082, 'quant_bits' : 8, 'fake_quant' : False}] * 5\n",
    "\n",
    "returned_power = [0]\n",
    "replace_linear_layers(model,  AdaPT_Linear, axx_list, total_macs, total_params, layer_count=[0], returned_power = returned_power, initialize = False)  \n",
    "print('Power of approximated operations: ', round(returned_power[0], 2), '%')\n",
    "print('Model compiled.')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# Run evaluation on the validation dataset\n",
    "top1, top5 = evaluate_imagenet(model, val_data, criterion, print_freq=1000, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c139533e-bab5-4144-9bf3-ad2497f7d839",
   "metadata": {},
   "source": [
    "## Run model retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ef59c-c29c-4bf6-afc4-1b4fb1e6bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.train import train_one_epoch\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5) # set desired learning rate\n",
    "\n",
    "#one epoch retrain\n",
    "train_one_epoch(model, criterion, optimizer, calib_data, device, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65da4f4-d0a9-4fe5-a70d-935ccb238c4a",
   "metadata": {},
   "source": [
    "## Re-run model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f6e1dd-07bb-4795-b0d6-34d7680f11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1, top5 = evaluate_imagenet(model, val_data, criterion, print_freq=1000, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
